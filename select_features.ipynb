{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "from music21 import *\n",
    "from itertools import chain, imap\n",
    "import csv\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fetch_genres(basedir):\n",
    "    genres = []\n",
    "    nested = os.listdir(basedir)\n",
    "    for i in nested:\n",
    "        try:\n",
    "            if(os.path.isdir(i) and not i.startswith(\".\")):\n",
    "                genres.append(i)\n",
    "        except:\n",
    "            print(\"An error occured trying to load features for genre \" + i)\n",
    "    return genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    for i in xrange(0, len(l), n):\n",
    "        yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatmap(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def failed_features(basedir):\n",
    "    not_included = set()\n",
    "    fs = features.jSymbolic.extractorsById\n",
    "    genres = fetch_genres(basedir)\n",
    "    for genre in genres:\n",
    "        try: \n",
    "            filename = basedir + \"/\" + genre + \"/features\"\n",
    "            files = os.listdir(filename)\n",
    "            for aFile in files:\n",
    "                if aFile.endswith(\".csv\"):\n",
    "                    arr = fileToArray(filename + \"/\" + aFile)\n",
    "                    arr1 = set(map(lambda x: tuple(x[0:2]), arr))\n",
    "                    # If features failed to extract \n",
    "                    for k in fs:\n",
    "                       if k is not \"I\":\n",
    "                            for i in range(len(fs[k])):\n",
    "                                if (k,str(i)) not in arr1 and fs[k][i] is not None:\n",
    "                                    not_included.add((k,i))\n",
    "        except:\n",
    "            print(\"An error occured trying to load features for genre \" + genre)\n",
    "    return not_included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_vectors(exclude_features, basedir):\n",
    "    genres = fetch_genres(basedir)\n",
    "    final_vecs = []\n",
    "    for genre in genres:\n",
    "        try:\n",
    "            filename = basedir + \"/\" + genre + \"/features\"\n",
    "            files = os.listdir(filename)\n",
    "            for aFile in files:\n",
    "                vec = []\n",
    "                if aFile.endswith(\".csv\"):\n",
    "                    arr = fileToArray(filename + \"/\" + aFile)\n",
    "                    for i in arr:\n",
    "                        if (i[0], int(i[1])) not in exclude_features:\n",
    "                            vec.append(map(lambda x: float(x), i[3:]))\n",
    "                if len(vec) > 0:\n",
    "                    final_vec = flatmap(vec)\n",
    "                    final_vec.append(genre)\n",
    "                    final_vecs.append(final_vec)\n",
    "        except:\n",
    "            print(\"Error occured trying to load features for \" + genre)\n",
    "    return final_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fileToArray(filename):\n",
    "    array = []\n",
    "    with open(filename, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        try:\n",
    "            array = list(reader)\n",
    "        except: \n",
    "            print(\"Error reading: \" + filename)\n",
    "    f.close()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perform_k_folds(k, vectors):\n",
    "    chunk_size = len(vectors) / k\n",
    "    chunked = chunks(vectors, chunk_size)\n",
    "    \n",
    "    sample_list = range(0, chunked)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occured trying to load features for genre classical\n",
      "Error occured trying to load features for classical\n",
      "149\n"
     ]
    }
   ],
   "source": [
    "basedir = \".\"\n",
    "\n",
    "# Features that failed to extract will not be written to files. Put all the failed\n",
    "# features into a set so that they can be excluded from the final vectors right away.\n",
    "not_included = failed_features(basedir)\n",
    "\n",
    "\n",
    "\n",
    "# Vectors is a list of lists. The inner list contains the features and the resulting\n",
    "# labels in the last position of each vector. \n",
    "vecs = build_vectors(not_included, basedir)\n",
    "\n",
    "print(str(len(vecs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333\n",
      "332\n",
      "136\n",
      "Feature ranking:\n",
      "1. feature 153 (0.016345)\n",
      "2. feature 213 (0.015885)\n",
      "3. feature 146 (0.015254)\n",
      "4. feature 223 (0.013520)\n",
      "5. feature 330 (0.012712)\n",
      "6. feature 221 (0.012007)\n",
      "7. feature 329 (0.011929)\n",
      "8. feature 289 (0.010957)\n",
      "9. feature 249 (0.010910)\n",
      "10. feature 197 (0.010870)\n",
      "11. feature 243 (0.010646)\n",
      "12. feature 292 (0.010560)\n",
      "13. feature 232 (0.010428)\n",
      "14. feature 299 (0.010406)\n",
      "15. feature 317 (0.010251)\n",
      "16. feature 295 (0.010242)\n",
      "17. feature 134 (0.010221)\n",
      "18. feature 7 (0.009884)\n",
      "19. feature 212 (0.009705)\n",
      "20. feature 215 (0.009664)\n",
      "21. feature 131 (0.009654)\n",
      "22. feature 233 (0.009636)\n",
      "23. feature 208 (0.009542)\n",
      "24. feature 152 (0.009542)\n",
      "25. feature 128 (0.009473)\n",
      "26. feature 219 (0.009196)\n",
      "27. feature 145 (0.009192)\n",
      "28. feature 158 (0.008886)\n",
      "29. feature 229 (0.008877)\n",
      "30. feature 218 (0.008703)\n",
      "31. feature 5 (0.008587)\n",
      "32. feature 135 (0.008524)\n",
      "33. feature 298 (0.008465)\n",
      "34. feature 305 (0.008317)\n",
      "35. feature 294 (0.007999)\n",
      "36. feature 237 (0.007980)\n",
      "37. feature 303 (0.007746)\n",
      "38. feature 3 (0.007712)\n",
      "39. feature 130 (0.007696)\n",
      "40. feature 4 (0.007643)\n",
      "41. feature 140 (0.007619)\n",
      "42. feature 9 (0.007458)\n",
      "43. feature 293 (0.007414)\n",
      "44. feature 319 (0.007299)\n",
      "45. feature 1 (0.007261)\n",
      "46. feature 302 (0.007186)\n",
      "47. feature 207 (0.007043)\n",
      "48. feature 19 (0.007035)\n",
      "49. feature 205 (0.006922)\n",
      "50. feature 11 (0.006901)\n",
      "51. feature 214 (0.006893)\n",
      "52. feature 234 (0.006559)\n",
      "53. feature 248 (0.006533)\n",
      "54. feature 159 (0.006470)\n",
      "55. feature 143 (0.006402)\n",
      "56. feature 23 (0.006300)\n",
      "57. feature 193 (0.006241)\n",
      "58. feature 202 (0.006233)\n",
      "59. feature 224 (0.006232)\n",
      "60. feature 149 (0.006230)\n",
      "61. feature 236 (0.006107)\n",
      "62. feature 211 (0.006103)\n",
      "63. feature 242 (0.006102)\n",
      "64. feature 147 (0.006064)\n",
      "65. feature 138 (0.006021)\n",
      "66. feature 196 (0.005913)\n",
      "67. feature 307 (0.005793)\n",
      "68. feature 154 (0.005767)\n",
      "69. feature 222 (0.005744)\n",
      "70. feature 296 (0.005674)\n",
      "71. feature 226 (0.005655)\n",
      "72. feature 139 (0.005630)\n",
      "73. feature 315 (0.005620)\n",
      "74. feature 241 (0.005539)\n",
      "75. feature 231 (0.005518)\n",
      "76. feature 27 (0.005445)\n",
      "77. feature 240 (0.005415)\n",
      "78. feature 17 (0.005391)\n",
      "79. feature 136 (0.005377)\n",
      "80. feature 210 (0.005370)\n",
      "81. feature 2 (0.005340)\n",
      "82. feature 20 (0.005334)\n",
      "83. feature 291 (0.005255)\n",
      "84. feature 230 (0.005246)\n",
      "85. feature 318 (0.005224)\n",
      "86. feature 321 (0.005155)\n",
      "87. feature 203 (0.005140)\n",
      "88. feature 316 (0.005069)\n",
      "89. feature 209 (0.004978)\n",
      "90. feature 308 (0.004967)\n",
      "91. feature 129 (0.004888)\n",
      "92. feature 310 (0.004845)\n",
      "93. feature 225 (0.004715)\n",
      "94. feature 141 (0.004610)\n",
      "95. feature 10 (0.004602)\n",
      "96. feature 297 (0.004547)\n",
      "97. feature 8 (0.004540)\n",
      "98. feature 195 (0.004521)\n",
      "99. feature 137 (0.004497)\n",
      "100. feature 0 (0.004497)\n",
      "101. feature 304 (0.004462)\n",
      "102. feature 246 (0.004395)\n",
      "103. feature 201 (0.004373)\n",
      "104. feature 16 (0.004349)\n",
      "105. feature 22 (0.004327)\n",
      "106. feature 50 (0.004278)\n",
      "107. feature 36 (0.004256)\n",
      "108. feature 157 (0.004193)\n",
      "109. feature 28 (0.004192)\n",
      "110. feature 192 (0.004052)\n",
      "111. feature 247 (0.004006)\n",
      "112. feature 41 (0.003978)\n",
      "113. feature 220 (0.003963)\n",
      "114. feature 227 (0.003922)\n",
      "115. feature 311 (0.003913)\n",
      "116. feature 331 (0.003854)\n",
      "117. feature 155 (0.003779)\n",
      "118. feature 239 (0.003740)\n",
      "119. feature 133 (0.003665)\n",
      "120. feature 29 (0.003628)\n",
      "121. feature 32 (0.003627)\n",
      "122. feature 40 (0.003624)\n",
      "123. feature 25 (0.003557)\n",
      "124. feature 6 (0.003504)\n",
      "125. feature 24 (0.003490)\n",
      "126. feature 156 (0.003490)\n",
      "127. feature 45 (0.003437)\n",
      "128. feature 13 (0.003436)\n",
      "129. feature 194 (0.003383)\n",
      "130. feature 251 (0.003329)\n",
      "131. feature 132 (0.003319)\n",
      "132. feature 235 (0.003316)\n",
      "133. feature 200 (0.003222)\n",
      "134. feature 238 (0.003212)\n",
      "135. feature 26 (0.003129)\n",
      "136. feature 252 (0.003126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rock\n",
      "['rock']\n",
      "1.0\n",
      "n_samples=149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.53333333  0.36666667  0.56666667  0.43333333  0.31034483]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import cross_validation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "print(str(len(vecs[0])))\n",
    "\n",
    "random.shuffle(vecs)\n",
    "\n",
    "X, y = map(lambda x: x[0:len(x)-1], vecs), map(lambda x: x[len(x)-1], vecs)\n",
    "\n",
    "print(str(len(X[0])))\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(X, y)\n",
    "importances = clf.feature_importances_ \n",
    "model = SelectFromModel(clf, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "X_new.shape\n",
    "\n",
    "print(str(len(X_new[0])))\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X_new.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"Feature importances\")\n",
    "# plt.bar(range(X_new.shape[1]), importances[indices], color=\"r\", yerr=std[indices], align=\"center\")\n",
    "# plt.xticks(range(X_new.shape[1]), indices)\n",
    "# plt.xlim([-1, X_new.shape[1]])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(verbose=1, n_estimators=100, random_state=0)\n",
    "clf = clf.fit(X_new, y)\n",
    "\n",
    "cur_idx = 38\n",
    "print(y[cur_idx])\n",
    "print(clf.predict(X_new[cur_idx]))\n",
    "print(clf.score(X_new, y))\n",
    "\n",
    "n_samples = X_new.shape[0]\n",
    "print(\"n_samples=\" + str(n_samples))\n",
    "\n",
    "print(str(cross_validation.cross_val_score(clf, X_new, y, cv=5)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
